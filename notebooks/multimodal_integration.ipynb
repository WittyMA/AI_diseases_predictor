{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-modal Integration for Disease Prediction\n",
    "\n",
    "This notebook demonstrates how to integrate tabular and image data for unified disease prediction. It covers feature fusion, unified model building, and evaluation of the multi-modal system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# --- 1. Load Pre-trained Models ---\n",
    "# Assuming you have already trained individual models using the respective notebooks\n",
    "\n",
    "def load_pretrained_models():\n",
    "    models = {}\n",
    "    preprocessors = {}\n",
    "    \n",
    "    print(\"Loading pre-trained models...\")\n",
    "    \n",
    "    # Load tabular models (example for diabetes)\n",
    "    try:\n",
    "        models['diabetes'] = joblib.load('diabetes_logistic_regression_model.pkl')\n",
    "        preprocessors['diabetes'] = joblib.load('diabetes_preprocessor.pkl')\n",
    "        print(\"Diabetes model loaded.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Diabetes model not found. Please train it first using the diabetes_prediction.ipynb notebook.\")\n",
    "    \n",
    "    # Load image models (example for pneumonia)\n",
    "    try:\n",
    "        models['pneumonia'] = load_model('pneumonia_detection_model.h5')\n",
    "        print(\"Pneumonia image model loaded.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Pneumonia image model not found: {e}. Please train it first using the chest_xray_pneumonia_detection.ipynb notebook.\")\n",
    "    \n",
    "    return models, preprocessors\n",
    "\n",
    "models, preprocessors = load_pretrained_models()\n",
    "\n",
    "# --- 2. Simulate Multi-modal Data ---\n",
    "# In a real scenario, you would load your actual datasets\n",
    "# For demonstration, we'll create synthetic data that represents features extracted from pre-trained models\n",
    "\n",
    "def simulate_multimodal_data(num_samples=1000):\n",
    "    print(\"Simulating multi-modal data...\")\n",
    "    \n",
    "    # Simulate tabular features (as if extracted from a tabular model)\n",
    "    tabular_features = np.random.rand(num_samples, 64)  # 64 features from tabular model\n",
    "    \n",
    "    # Simulate image features (as if extracted from an image model)\n",
    "    image_features = np.random.rand(num_samples, 128)   # 128 features from image model\n",
    "    \n",
    "    # Simulate unified target (combining information from both modalities)\n",
    "    # In reality, this would be your ground truth labels\n",
    "    unified_target = np.random.randint(0, 2, num_samples)\n",
    "    \n",
    "    return tabular_features, image_features, unified_target\n",
    "\n",
    "tabular_features, image_features, unified_target = simulate_multimodal_data()\n",
    "\n",
    "print(f\"Tabular features shape: {tabular_features.shape}\")\n",
    "print(f\"Image features shape: {image_features.shape}\")\n",
    "print(f\"Unified target shape: {unified_target.shape}\")\n",
    "\n",
    "# --- 3. Split Data for Training ---\n",
    "X_tab_train, X_tab_test, X_img_train, X_img_test, y_train, y_test = train_test_split(\n",
    "    tabular_features, image_features, unified_target, \n",
    "    test_size=0.2, random_state=42, stratify=unified_target\n",
    ")\n",
    "\n",
    "print(\"Data split for multi-modal training:\")\n",
    "print(f\"Training tabular features: {X_tab_train.shape}\")\n",
    "print(f\"Training image features: {X_img_train.shape}\")\n",
    "print(f\"Training targets: {y_train.shape}\")\n",
    "\n",
    "# --- 4. Build Unified Multi-modal Model ---\n",
    "def build_unified_model(tabular_features_dim, image_features_dim, num_classes=2):\n",
    "    \"\"\"\n",
    "    Builds a unified prediction model that takes fused features as input.\n",
    "    \"\"\"\n",
    "    # Input layers for each modality's features\n",
    "    input_tabular = Input(shape=(tabular_features_dim,), name='tabular_features_input')\n",
    "    input_image = Input(shape=(image_features_dim,), name='image_features_input')\n",
    "    \n",
    "    # Optional: Add modality-specific processing layers\n",
    "    tabular_processed = Dense(32, activation='relu')(input_tabular)\n",
    "    tabular_processed = Dropout(0.3)(tabular_processed)\n",
    "    \n",
    "    image_processed = Dense(64, activation='relu')(input_image)\n",
    "    image_processed = Dropout(0.3)(image_processed)\n",
    "    \n",
    "    # Concatenate features (Feature Fusion)\n",
    "    merged_features = Concatenate()([tabular_processed, image_processed])\n",
    "    \n",
    "    # Add dense layers for the unified model\n",
    "    x = Dense(128, activation='relu')(merged_features)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    if num_classes > 2:\n",
    "        output = Dense(num_classes, activation='softmax')(x)\n",
    "        loss = 'categorical_crossentropy'\n",
    "    else:\n",
    "        output = Dense(1, activation='sigmoid')(x)\n",
    "        loss = 'binary_crossentropy'\n",
    "    \n",
    "    unified_model = Model(inputs=[input_tabular, input_image], outputs=output)\n",
    "    unified_model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    return unified_model\n",
    "\n",
    "# Build the unified model\n",
    "unified_model = build_unified_model(tabular_features.shape[1], image_features.shape[1])\n",
    "unified_model.summary()\n",
    "\n",
    "# --- 5. Train the Unified Model ---\n",
    "print(\"\\nTraining unified multi-modal model...\")\n",
    "\n",
    "history = unified_model.fit(\n",
    "    [X_tab_train, X_img_train], y_train,\n",
    "    epochs=20, \n",
    "    batch_size=32,\n",
    "    validation_data=([X_tab_test, X_img_test], y_test),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Unified multi-modal model training complete.\")\n",
    "\n",
    "# --- 6. Plot Training History ---\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Multi-modal Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot loss\n",
    "    ax2.plot(history.history['loss'], label='Training Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Multi-modal Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# --- 7. Evaluate the Unified Model ---\n",
    "print(\"\\nEvaluating unified multi-modal model...\")\n",
    "\n",
    "# Evaluate on test set\n",
    "loss, accuracy = unified_model.evaluate([X_tab_test, X_img_test], y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "y_pred_proba = unified_model.predict([X_tab_test, X_img_test]).flatten()\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"\\nDetailed Metrics:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - Multi-modal Model\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Multi-modal Model')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- 8. Compare with Individual Modalities ---\n",
    "print(\"\\n--- Comparison with Individual Modalities ---\")\n",
    "\n",
    "# Train models on individual modalities for comparison\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Tabular-only model\n",
    "tabular_only_model = LogisticRegression(random_state=42)\n",
    "tabular_only_model.fit(X_tab_train, y_train)\n",
    "tabular_pred = tabular_only_model.predict(X_tab_test)\n",
    "tabular_accuracy = accuracy_score(y_test, tabular_pred)\n",
    "print(f\"Tabular-only model accuracy: {tabular_accuracy:.4f}\")\n",
    "\n",
    "# Image-only model\n",
    "image_only_model = LogisticRegression(random_state=42)\n",
    "image_only_model.fit(X_img_train, y_train)\n",
    "image_pred = image_only_model.predict(X_img_test)\n",
    "image_accuracy = accuracy_score(y_test, image_pred)\n",
    "print(f\"Image-only model accuracy: {image_accuracy:.4f}\")\n",
    "\n",
    "print(f\"Multi-modal model accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Visualization of comparison\n",
    "comparison_data = {\n",
    "    'Model': ['Tabular Only', 'Image Only', 'Multi-modal'],\n",
    "    'Accuracy': [tabular_accuracy, image_accuracy, accuracy]\n",
    "}\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=comparison_df, x='Model', y='Accuracy')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(comparison_df['Accuracy']):\n",
    "    plt.text(i, v + 0.01, f'{v:.3f}', ha='center')\n",
    "plt.show()\n",
    "\n",
    "# --- 9. Save the Unified Model ---\n",
    "unified_model.save('unified_multimodal_model.h5')\n",
    "print(\"\\nUnified multi-modal model saved as 'unified_multimodal_model.h5'\")\n",
    "\n",
    "# --- 10. Prediction Function for New Data ---\n",
    "def predict_multimodal(tabular_features, image_features, model):\n",
    "    \"\"\"\n",
    "    Makes predictions using the unified multi-modal model.\n",
    "    \n",
    "    Args:\n",
    "        tabular_features: Preprocessed tabular features\n",
    "        image_features: Extracted image features\n",
    "        model: Trained unified model\n",
    "    \n",
    "    Returns:\n",
    "        prediction, confidence\n",
    "    \"\"\"\n",
    "    prediction_proba = model.predict([tabular_features, image_features])[0][0]\n",
    "    prediction = 1 if prediction_proba > 0.5 else 0\n",
    "    confidence = prediction_proba if prediction == 1 else 1 - prediction_proba\n",
    "    \n",
    "    return prediction, confidence\n",
    "\n",
    "# Example usage\n",
    "sample_tabular = X_tab_test[:1]  # First test sample\n",
    "sample_image = X_img_test[:1]    # First test sample\n",
    "pred, conf = predict_multimodal(sample_tabular, sample_image, unified_model)\n",
    "print(f\"\\nSample prediction: {pred} (Confidence: {conf:.4f})\")\n",
    "print(f\"Actual label: {y_test[0]}\")\n",
    "\n",
    "print(\"\\nMulti-modal integration complete!\")\n",
    "print(\"This notebook demonstrates the power of combining multiple data modalities for improved prediction accuracy.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

